{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text=\"\"\n",
    "    pdf_reader= PdfReader(pdf_docs)\n",
    "    for page in pdf_reader.pages:\n",
    "        text+= page.extract_text()\n",
    "    return  text\n",
    "\n",
    "\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=1000)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_vector_store(text_chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nProject Proposal  Guideline  \\nMake sure everyone in your team approves of the proposal. Then, only one member \\nneeds to submit the PDF of your proposal to Canvas as described below:  \\n \\nProject Name, Participants, and Work flow  \\nGive the project a good name and roles of participants in as much detail as possible. \\nDocument how will you work collaboratively on the project. For example, are you \\ngoing to have weekly meetings outside class? When?  \\n \\nProject Abstract  \\nInclude 1 -3 paragraphs explaining your project. This abstract should focus on the \\ngoal of the project from a user’s perspective rather than the underlying \\nimplementation methods you will use. Describe your target and Actions and  provide \\na workflow diagram with explanation.  \\n \\nData Abstraction  \\nList the types and attributes of the dataset, and a detailed description of dataset.  \\n \\nProject Design  \\nList the underlying technologies and design methods in as much detail as possible. \\nFor example, which software, IDEs, packages,  and modules are you expecting  to use? \\nWhat functions are you expecting to create? What is your programming logic?  \\n \\nState of the art  \\nWhen writing the state of the art, it's essential to conduct thorough research, \\nfocusing on the most recent developments in your project's domain, while providing \\nproper citations from authoritative sources. Compare and contrast various \\napproaches, highlig ht historical context, and identify gaps or challenges your project \\nintends to address. Keep it concise, objective, and use visual aids when necessary to \\neffectively convey the latest trends and advancements in the field . \\n \\nProject Milestones  \\nList as many verifiable milestones as possible between now and the completion of \\nthe project. Identify incremental features. The goal is to work on a project that will \\nallow incremental development. Try to be realistic and stick to them. Also, for the \\nmore  ambitious projects, try to have a less ambitious but functioning system early on \\nso that if you fall short of your goals you will still have something to show for it.  \\n \\nProject Expe cted Result  \\nPlease clarifying project objectives and ensuring everyone involved understands the \\nproject's ultimate goals. It involves providing a clear, concise, and comprehensive \\ndescription of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \\nprogress tracking . \\n \\nReference Material  \\nIt is always in your best interest to use code from others whenever possible. If you will \\nbe using or modifying significant amounts of code from a third party, mention it here. \\nStandard libraries/imports need not be mentioned, but if it requires a separate  \\ndownload should be . It is acceptable to read code from others for ideas and syntax, \\nbut if you claim you wrote a particular function, you MUST document if any significant \\nportion of it came directly from another source.  Also, for projects that require data, \\nyou must mention the source of the data.  \\n \\nThe project proposal should encompass a wide range of topics, including but not \\nlimited to those listed here. These topics form the essential framework for outlining \\nthe project's scope, objectives, methodology, expected outcomes, and resource \\nrequirements . However, the proposal may also include  additional relevant details and \\nconsiderations specific to the project's unique needs and goals . \\n \\n \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = get_pdf_text(r\"E:\\unt\\spring_2024\\info retrieval\\project\\Project Proposal Guideline.pdf\")\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = get_text_chunks(raw_text)\n",
    "get_vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain():\n",
    "\n",
    "    prompt_template =  \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)\n",
    "\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input(user_question):\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    \n",
    "    new_db = new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search_with_score(user_question)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in docs])\n",
    "    prompt = PROMPT_TEMPLATE.format(context=context_text, question=user_question,return_only_outputs=True)\n",
    "    print(prompt)\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\")\n",
    "    answer = chain.run(input_documents=docs, question=user_question)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Project Proposal  Guideline  \\nMake sure everyone in your team approves of the proposal. Then, only one member \\nneeds to submit the PDF of your proposal to Canvas as described below:  \\n \\nProject Name, Participants, and Work flow  \\nGive the project a good name and roles of participants in as much detail as possible. \\nDocument how will you work collaboratively on the project. For example, are you \\ngoing to have weekly meetings outside class? When?  \\n \\nProject Abstract  \\nInclude 1 -3 paragraphs explaining your project. This abstract should focus on the \\ngoal of the project from a user’s perspective rather than the underlying \\nimplementation methods you will use. Describe your target and Actions and  provide \\na workflow diagram with explanation.  \\n \\nData Abstraction  \\nList the types and attributes of the dataset, and a detailed description of dataset.  \\n \\nProject Design  \\nList the underlying technologies and design methods in as much detail as possible. \\nFor example, which software, IDEs, packages,  and modules are you expecting  to use? \\nWhat functions are you expecting to create? What is your programming logic?  \\n \\nState of the art  \\nWhen writing the state of the art, it's essential to conduct thorough research, \\nfocusing on the most recent developments in your project's domain, while providing \\nproper citations from authoritative sources. Compare and contrast various \\napproaches, highlig ht historical context, and identify gaps or challenges your project \\nintends to address. Keep it concise, objective, and use visual aids when necessary to \\neffectively convey the latest trends and advancements in the field . \\n \\nProject Milestones  \\nList as many verifiable milestones as possible between now and the completion of \\nthe project. Identify incremental features. The goal is to work on a project that will \\nallow incremental development. Try to be realistic and stick to them. Also, for the \\nmore  ambitious projects, try to have a less ambitious but functioning system early on \\nso that if you fall short of your goals you will still have something to show for it.  \\n \\nProject Expe cted Result  \\nPlease clarifying project objectives and ensuring everyone involved understands the \\nproject's ultimate goals. It involves providing a clear, concise, and comprehensive \\ndescription of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \\nprogress tracking . \\n \\nReference Material  \\nIt is always in your best interest to use code from others whenever possible. If you will \\nbe using or modifying significant amounts of code from a third party, mention it here. \\nStandard libraries/imports need not be mentioned, but if it requires a separate  \\ndownload should be . It is acceptable to read code from others for ideas and syntax, \\nbut if you claim you wrote a particular function, you MUST document if any significant \\nportion of it came directly from another source.  Also, for projects that require data, \\nyou must mention the source of the data.  \\n \\nThe project proposal should encompass a wide range of topics, including but not \\nlimited to those listed here. These topics form the essential framework for outlining \\nthe project's scope, objectives, methodology, expected outcomes, and resource \\nrequirements . However, the proposal may also include  additional relevant details and \\nconsiderations specific to the project's unique needs and goals .\")]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43muser_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow many members can a team be\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 15\u001b[0m, in \u001b[0;36muser_input\u001b[1;34m(user_question)\u001b[0m\n\u001b[0;32m     13\u001b[0m docs \u001b[38;5;241m=\u001b[39m new_db\u001b[38;5;241m.\u001b[39msimilarity_search(user_question)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs)\n\u001b[1;32m---> 15\u001b[0m context_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc, _score \u001b[38;5;129;01min\u001b[39;00m docs])\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(context\u001b[38;5;241m=\u001b[39mcontext_text, question\u001b[38;5;241m=\u001b[39muser_question,return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n",
      "Cell \u001b[1;32mIn[42], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m docs \u001b[38;5;241m=\u001b[39m new_db\u001b[38;5;241m.\u001b[39msimilarity_search(user_question)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs)\n\u001b[1;32m---> 15\u001b[0m context_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc, _score \u001b[38;5;129;01min\u001b[39;00m docs])\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(context\u001b[38;5;241m=\u001b[39mcontext_text, question\u001b[38;5;241m=\u001b[39muser_question,return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "user_input(\"how many members can a team be\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'how many members can a team be',\n",
       " 'result': 'Answer is not available in the context',\n",
       " 'source_documents': [Document(page_content=\"Project Proposal  Guideline  \\nMake sure everyone in your team approves of the proposal. Then, only one member \\nneeds to submit the PDF of your proposal to Canvas as described below:  \\n \\nProject Name, Participants, and Work flow  \\nGive the project a good name and roles of participants in as much detail as possible. \\nDocument how will you work collaboratively on the project. For example, are you \\ngoing to have weekly meetings outside class? When?  \\n \\nProject Abstract  \\nInclude 1 -3 paragraphs explaining your project. This abstract should focus on the \\ngoal of the project from a user’s perspective rather than the underlying \\nimplementation methods you will use. Describe your target and Actions and  provide \\na workflow diagram with explanation.  \\n \\nData Abstraction  \\nList the types and attributes of the dataset, and a detailed description of dataset.  \\n \\nProject Design  \\nList the underlying technologies and design methods in as much detail as possible. \\nFor example, which software, IDEs, packages,  and modules are you expecting  to use? \\nWhat functions are you expecting to create? What is your programming logic?  \\n \\nState of the art  \\nWhen writing the state of the art, it's essential to conduct thorough research, \\nfocusing on the most recent developments in your project's domain, while providing \\nproper citations from authoritative sources. Compare and contrast various \\napproaches, highlig ht historical context, and identify gaps or challenges your project \\nintends to address. Keep it concise, objective, and use visual aids when necessary to \\neffectively convey the latest trends and advancements in the field . \\n \\nProject Milestones  \\nList as many verifiable milestones as possible between now and the completion of \\nthe project. Identify incremental features. The goal is to work on a project that will \\nallow incremental development. Try to be realistic and stick to them. Also, for the \\nmore  ambitious projects, try to have a less ambitious but functioning system early on \\nso that if you fall short of your goals you will still have something to show for it.  \\n \\nProject Expe cted Result  \\nPlease clarifying project objectives and ensuring everyone involved understands the \\nproject's ultimate goals. It involves providing a clear, concise, and comprehensive \\ndescription of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \\nprogress tracking . \\n \\nReference Material  \\nIt is always in your best interest to use code from others whenever possible. If you will \\nbe using or modifying significant amounts of code from a third party, mention it here. \\nStandard libraries/imports need not be mentioned, but if it requires a separate  \\ndownload should be . It is acceptable to read code from others for ideas and syntax, \\nbut if you claim you wrote a particular function, you MUST document if any significant \\nportion of it came directly from another source.  Also, for projects that require data, \\nyou must mention the source of the data.  \\n \\nThe project proposal should encompass a wide range of topics, including but not \\nlimited to those listed here. These topics form the essential framework for outlining \\nthe project's scope, objectives, methodology, expected outcomes, and resource \\nrequirements . However, the proposal may also include  additional relevant details and \\nconsiderations specific to the project's unique needs and goals .\")]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question=\"how many members can a team be\"\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "\n",
    "new_db = new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "retriever = new_db.as_retriever(score_threshold = 0.7)\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                            temperature=0.6)\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=model,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "chain(\"how many members can a team be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Search\n",
      "Action Input: How old is Taylor Swift?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m34 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 34\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'34'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "tools=load_tools([\"serpapi\",\"llm-math\"],llm=model)\n",
    "agent_exe=initialize_agent(\n",
    "    tools,\n",
    "    model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
    "agent_exe.run(\"what is taylor swifts age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Project Proposal  Guideline  \\nMake sure everyone in your team approves of the proposal. Then, only one member \\nneeds to submit the PDF of your proposal to Canvas as described below:  \\n \\nProject Name, Participants, and Work flow  \\nGive the project a good name and roles of participants in as much detail as possible. \\nDocument how will you work collaboratively on the project. For example, are you \\ngoing to have weekly meetings outside class? When?  \\n \\nProject Abstract  \\nInclude 1 -3 paragraphs explaining your project. This abstract should focus on the \\ngoal of the project from a user’s perspective rather than the underlying \\nimplementation methods you will use. Describe your target and Actions and  provide \\na workflow diagram with explanation.  \\n \\nData Abstraction  \\nList the types and attributes of the dataset, and a detailed description of dataset.  \\n \\nProject Design  \\nList the underlying technologies and design methods in as much detail as possible. \\nFor example, which software, IDEs, packages,  and modules are you expecting  to use? \\nWhat functions are you expecting to create? What is your programming logic?  \\n \\nState of the art  \\nWhen writing the state of the art, it's essential to conduct thorough research, \\nfocusing on the most recent developments in your project's domain, while providing \\nproper citations from authoritative sources. Compare and contrast various \\napproaches, highlig ht historical context, and identify gaps or challenges your project \\nintends to address. Keep it concise, objective, and use visual aids when necessary to \\neffectively convey the latest trends and advancements in the field . \\n \\nProject Milestones  \\nList as many verifiable milestones as possible between now and the completion of \\nthe project. Identify incremental features. The goal is to work on a project that will \\nallow incremental development. Try to be realistic and stick to them. Also, for the \\nmore  ambitious projects, try to have a less ambitious but functioning system early on \\nso that if you fall short of your goals you will still have something to show for it.  \\n \\nProject Expe cted Result  \\nPlease clarifying project objectives and ensuring everyone involved understands the \\nproject's ultimate goals. It involves providing a clear, concise, and comprehensive \\ndescription of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \\nprogress tracking . \\n \\nReference Material  \\nIt is always in your best interest to use code from others whenever possible. If you will \\nbe using or modifying significant amounts of code from a third party, mention it here. \\nStandard libraries/imports need not be mentioned, but if it requires a separate  \\ndownload should be . It is acceptable to read code from others for ideas and syntax, \\nbut if you claim you wrote a particular function, you MUST document if any significant \\nportion of it came directly from another source.  Also, for projects that require data, \\nyou must mention the source of the data.  \\n \\nThe project proposal should encompass a wide range of topics, including but not \\nlimited to those listed here. These topics form the essential framework for outlining \\nthe project's scope, objectives, methodology, expected outcomes, and resource \\nrequirements . However, the proposal may also include  additional relevant details and \\nconsiderations specific to the project's unique needs and goals .\")]\n",
      "\n",
      "    Answer the question as detailed as possible from the provided context, make sure to provide all the details. If the answer is not in the provided context, just say, \"answer is not available in the context\". Don't provide the wrong answer.\n",
      "\n",
      "    Context:\n",
      "    Project Proposal  Guideline  \n",
      "Make sure everyone in your team approves of the proposal. Then, only one member \n",
      "needs to submit the PDF of your proposal to Canvas as described below:  \n",
      " \n",
      "Project Name, Participants, and Work flow  \n",
      "Give the project a good name and roles of participants in as much detail as possible. \n",
      "Document how will you work collaboratively on the project. For example, are you \n",
      "going to have weekly meetings outside class? When?  \n",
      " \n",
      "Project Abstract  \n",
      "Include 1 -3 paragraphs explaining your project. This abstract should focus on the \n",
      "goal of the project from a user’s perspective rather than the underlying \n",
      "implementation methods you will use. Describe your target and Actions and  provide \n",
      "a workflow diagram with explanation.  \n",
      " \n",
      "Data Abstraction  \n",
      "List the types and attributes of the dataset, and a detailed description of dataset.  \n",
      " \n",
      "Project Design  \n",
      "List the underlying technologies and design methods in as much detail as possible. \n",
      "For example, which software, IDEs, packages,  and modules are you expecting  to use? \n",
      "What functions are you expecting to create? What is your programming logic?  \n",
      " \n",
      "State of the art  \n",
      "When writing the state of the art, it's essential to conduct thorough research, \n",
      "focusing on the most recent developments in your project's domain, while providing \n",
      "proper citations from authoritative sources. Compare and contrast various \n",
      "approaches, highlig ht historical context, and identify gaps or challenges your project \n",
      "intends to address. Keep it concise, objective, and use visual aids when necessary to \n",
      "effectively convey the latest trends and advancements in the field . \n",
      " \n",
      "Project Milestones  \n",
      "List as many verifiable milestones as possible between now and the completion of \n",
      "the project. Identify incremental features. The goal is to work on a project that will \n",
      "allow incremental development. Try to be realistic and stick to them. Also, for the \n",
      "more  ambitious projects, try to have a less ambitious but functioning system early on \n",
      "so that if you fall short of your goals you will still have something to show for it.  \n",
      " \n",
      "Project Expe cted Result  \n",
      "Please clarifying project objectives and ensuring everyone involved understands the \n",
      "project's ultimate goals. It involves providing a clear, concise, and comprehensive \n",
      "description of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \n",
      "progress tracking . \n",
      " \n",
      "Reference Material  \n",
      "It is always in your best interest to use code from others whenever possible. If you will \n",
      "be using or modifying significant amounts of code from a third party, mention it here. \n",
      "Standard libraries/imports need not be mentioned, but if it requires a separate  \n",
      "download should be . It is acceptable to read code from others for ideas and syntax, \n",
      "but if you claim you wrote a particular function, you MUST document if any significant \n",
      "portion of it came directly from another source.  Also, for projects that require data, \n",
      "you must mention the source of the data.  \n",
      " \n",
      "The project proposal should encompass a wide range of topics, including but not \n",
      "limited to those listed here. These topics form the essential framework for outlining \n",
      "the project's scope, objectives, methodology, expected outcomes, and resource \n",
      "requirements . However, the proposal may also include  additional relevant details and \n",
      "considerations specific to the project's unique needs and goals .?\n",
      "\n",
      "    Question:\n",
      "    how many members can a team be\n",
      "\n",
      "    Answer:\n",
      "    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SystemMessages are not yet supported!\n\nTo automatically convert the leading SystemMessage to a HumanMessage,\nset  `convert_system_message_to_human` to True. Example:\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m     25\u001b[0m chain1 \u001b[38;5;241m=\u001b[39m load_qa_chain(model, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_reduce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mchain1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:550\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    546\u001b[0m         _output_key\n\u001b[0;32m    547\u001b[0m     ]\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    551\u001b[0m         _output_key\n\u001b[0;32m    552\u001b[0m     ]\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    376\u001b[0m }\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[0;32m    138\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[0;32m    139\u001b[0m )\n\u001b[0;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:226\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    216\u001b[0m     docs: List[Document],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[0;32m    232\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    233\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[0;32m    236\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:227\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[0;32m    229\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:224\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    219\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    220\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    221\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[0;32m    222\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    116\u001b[0m         prompts,\n\u001b[0;32m    117\u001b[0m         stop,\n\u001b[0;32m    118\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    124\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    565\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    569\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    570\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:434\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    433\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 434\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    435\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    436\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    438\u001b[0m ]\n\u001b[0;32m    439\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:424\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 424\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    425\u001b[0m                 m,\n\u001b[0;32m    426\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    427\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    428\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    429\u001b[0m             )\n\u001b[0;32m    430\u001b[0m         )\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:608\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m         )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 608\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    609\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:557\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    552\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    556\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m--> 557\u001b[0m     params, chat, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(\n\u001b[0;32m    558\u001b[0m         messages,\n\u001b[0;32m    559\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m     response: genai\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mGenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m    563\u001b[0m         content\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    565\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39mchat\u001b[38;5;241m.\u001b[39msend_message,\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:657\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._prepare_chat\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m     client \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\n\u001b[0;32m    653\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tools\u001b[38;5;241m=\u001b[39mtools, safety_settings\u001b[38;5;241m=\u001b[39msafety_settings\n\u001b[0;32m    654\u001b[0m     )\n\u001b[0;32m    656\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_params(stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 657\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_chat_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_system_message_to_human\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_system_message_to_human\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m message \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    662\u001b[0m chat \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mstart_chat(history\u001b[38;5;241m=\u001b[39mhistory)\n",
      "File \u001b[1;32mc:\\Users\\jashi\\anaconda3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:313\u001b[0m, in \u001b[0;36m_parse_chat_history\u001b[1;34m(input_messages, convert_system_message_to_human)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    309\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, SystemMessage)\n\u001b[0;32m    311\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m convert_system_message_to_human\n\u001b[0;32m    312\u001b[0m         ):\n\u001b[1;32m--> 313\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    314\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"SystemMessages are not yet supported!\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03mTo automatically convert the leading SystemMessage to a HumanMessage,\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03mset  `convert_system_message_to_human` to True. Example:\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03mllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    321\u001b[0m             )\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, SystemMessage):\n\u001b[0;32m    323\u001b[0m             raw_system_message \u001b[38;5;241m=\u001b[39m message\n",
      "\u001b[1;31mValueError\u001b[0m: SystemMessages are not yet supported!\n\nTo automatically convert the leading SystemMessage to a HumanMessage,\nset  `convert_system_message_to_human` to True. Example:\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n"
     ]
    }
   ],
   "source": [
    "user_question = \"how many members can a team be\"\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details. If the answer is not in the provided context, just say, \"answer is not available in the context\". Don't provide the wrong answer.\n",
    "\n",
    "    Context:\n",
    "    {context}?\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(user_question)\n",
    "print(docs)\n",
    "\n",
    "context_text = docs[0].page_content\n",
    "prompt = PROMPT_TEMPLATE.format(context=context_text, question=user_question)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "chain1 = load_qa_chain(model, chain_type=\"map_reduce\")\n",
    "answer = chain1.run(input_documents=docs, question=user_question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Project Proposal  Guideline  \\nMake sure everyone in your team approves of the proposal. Then, only one member \\nneeds to submit the PDF of your proposal to Canvas as described below:  \\n \\nProject Name, Participants, and Work flow  \\nGive the project a good name and roles of participants in as much detail as possible. \\nDocument how will you work collaboratively on the project. For example, are you \\ngoing to have weekly meetings outside class? When?  \\n \\nProject Abstract  \\nInclude 1 -3 paragraphs explaining your project. This abstract should focus on the \\ngoal of the project from a user’s perspective rather than the underlying \\nimplementation methods you will use. Describe your target and Actions and  provide \\na workflow diagram with explanation.  \\n \\nData Abstraction  \\nList the types and attributes of the dataset, and a detailed description of dataset.  \\n \\nProject Design  \\nList the underlying technologies and design methods in as much detail as possible. \\nFor example, which software, IDEs, packages,  and modules are you expecting  to use? \\nWhat functions are you expecting to create? What is your programming logic?  \\n \\nState of the art  \\nWhen writing the state of the art, it's essential to conduct thorough research, \\nfocusing on the most recent developments in your project's domain, while providing \\nproper citations from authoritative sources. Compare and contrast various \\napproaches, highlig ht historical context, and identify gaps or challenges your project \\nintends to address. Keep it concise, objective, and use visual aids when necessary to \\neffectively convey the latest trends and advancements in the field . \\n \\nProject Milestones  \\nList as many verifiable milestones as possible between now and the completion of \\nthe project. Identify incremental features. The goal is to work on a project that will \\nallow incremental development. Try to be realistic and stick to them. Also, for the \\nmore  ambitious projects, try to have a less ambitious but functioning system early on \\nso that if you fall short of your goals you will still have something to show for it.  \\n \\nProject Expe cted Result  \\nPlease clarifying project objectives and ensuring everyone involved understands the \\nproject's ultimate goals. It involves providing a clear, concise, and comprehensive \\ndescription of what the project is expected to achieve. The expected results should be specific and measurable, serving as a benchmark for success and facilitating \\nprogress tracking . \\n \\nReference Material  \\nIt is always in your best interest to use code from others whenever possible. If you will \\nbe using or modifying significant amounts of code from a third party, mention it here. \\nStandard libraries/imports need not be mentioned, but if it requires a separate  \\ndownload should be . It is acceptable to read code from others for ideas and syntax, \\nbut if you claim you wrote a particular function, you MUST document if any significant \\nportion of it came directly from another source.  Also, for projects that require data, \\nyou must mention the source of the data.  \\n \\nThe project proposal should encompass a wide range of topics, including but not \\nlimited to those listed here. These topics form the essential framework for outlining \\nthe project's scope, objectives, methodology, expected outcomes, and resource \\nrequirements . However, the proposal may also include  additional relevant details and \\nconsiderations specific to the project's unique needs and goals .\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs[0])\n",
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain():\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)\n",
    "\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "    return chain\n",
    "\n",
    "\n",
    "\n",
    "def user_input(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    \n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "\n",
    "    chain = get_conversational_chain()\n",
    "\n",
    "    \n",
    "    response = chain(\n",
    "        {\"input_documents\":docs, \"question\": user_question}\n",
    "        , return_only_outputs=True)\n",
    "\n",
    "    print(response)\n",
    "    st.write(\"Reply: \", response[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 01:32:08.465 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\jashi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.set_page_config(\"Chat PDF\")\n",
    "    st.header(\"Chat with PDF using Gemini💁\")\n",
    "\n",
    "    user_question = st.text_input(\"Ask a Question from the PDF Files\")\n",
    "\n",
    "    if user_question:\n",
    "        user_input(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.title(\"Menu:\")\n",
    "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
    "        if st.button(\"Submit & Process\"):\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                raw_text = get_pdf_text(pdf_docs)\n",
    "                text_chunks = get_text_chunks(raw_text)\n",
    "                get_vector_store(text_chunks)\n",
    "                st.success(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run st.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
